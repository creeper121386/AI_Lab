{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-30T09:50:54.598Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as T\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "from model2 import G, D\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-30T09:50:54.603Z"
    }
   },
   "outputs": [],
   "source": [
    "################## init Function ########################\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() and cuda else torch.device('cpu')\n",
    "transform = T.Compose([T.Resize(imgSize), T.ToTensor()])\n",
    "# transform = T.Compose([T.Resize(400), T.RandomCrop(imgSize), T.ToTensor()])\n",
    "\n",
    "\n",
    "class whyDataset(Dataset):\n",
    "    def __init__(self, imgPath):\n",
    "        self.path = imgPath\n",
    "        self.fileList = os.listdir(self.path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fileList) if not sampleNum else sampleNum\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        path = self.path + '/' + self.fileList[ix]\n",
    "        img = Image.open(path)\n",
    "        img = transform(img)\n",
    "        return img, 1   # real label\n",
    "\n",
    "\n",
    "class GP_loss(nn.Module):\n",
    "    def __init__(self, lamda=10):\n",
    "        super(GP_loss, self).__init__()\n",
    "        self.lamda = lamda\n",
    "        return\n",
    "\n",
    "    def forward(self, D_output1, D_output2, x_grad):\n",
    "        grad = (x_grad**2).sum(1).sum(1).sum(1)\n",
    "        tmp = self.lamda * (torch.sqrt(grad) - 1)**2\n",
    "        return torch.mean(D_output1-D_output2+tmp)\n",
    "        # Loss = D(x_new)-D(x)+lambda(||grad(D(x_new))||_2 -1)^2, for D(x_new)=D_output1, D(x)=D_output2.\n",
    "\n",
    "\n",
    "# def show(img):\n",
    "#     # img = T.ToPILImage(img)\n",
    "#     img = img.numpy()\n",
    "#     plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "#     # plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-30T09:50:54.609Z"
    }
   },
   "outputs": [],
   "source": [
    "class WGAN(object):\n",
    "    def __init__(self):\n",
    "        Dnn = D()\n",
    "        Gnn = G()\n",
    "        self.Dnn = Dnn.to(device)\n",
    "        self.Gnn = Gnn.to(device)\n",
    "        self.D_optim = optim.Adam(\n",
    "            self.Dnn.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        self.G_optim = optim.Adam(\n",
    "            self.Gnn.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        self.G_loss = []\n",
    "        self.D_loss = []\n",
    "        self.one = torch.FloatTensor([1]).to(device)\n",
    "        self.n_one = self.one * -1\n",
    "\n",
    "    def saveModel(self, No):\n",
    "        torch.save(self.Gnn.state_dict(), modelPath +\n",
    "                   \"/WGAN_G-epoch{}.pkl\".format(No))\n",
    "        torch.save(self.Dnn.state_dict(), modelPath +\n",
    "                   \"/WGAN_D-epoch{}.pkl\".format(No))\n",
    "        print(\"[save] WGAN_G-epoch{}.pkl, WGAN_D-epoch{}.pkl saved.\".format(No, No))\n",
    "\n",
    "    def saveLoss(self, path):\n",
    "        if writeData:\n",
    "            G = np.array(self.Gnn)\n",
    "            D = np.array(self.Dnn)\n",
    "            np.savetxt(path+'/Gdata-WGAN.txt', G)\n",
    "            np.savetxt(path+'/Ddata-WGAN.txt', D)\n",
    "\n",
    "    def calc_gradient_penalty(self, real_data, fake_data):\n",
    "        alpha = torch.rand(batchSize, 1).to(device)\n",
    "        alpha = alpha.expand(batchSize, real_data.nelement(\n",
    "        )/batchSize).contiguous().view(batchSize, 3, imgSize, imgSize)\n",
    "\n",
    "        new = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "        new = new.to(device)\n",
    "        new = autograd.Variable(new, requires_grad=True)\n",
    "        pred = self.Dnn(new)\n",
    "        grad = autograd.grad(outputs=pred, inputs=new,\n",
    "                                  grad_outputs=torch.ones(pred.size()).to(device),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        grad = grad.view(grad.size(0), -1)\n",
    "        loss = ((grad.norm(2, dim=1) - 1)** 2).mean() * lamda\n",
    "        return loss\n",
    "\n",
    "    def step_D(self, real):\n",
    "        gploss = GP_loss()\n",
    "        noise = torch.randn(batchSize, nz, 1, 1).to(device)\n",
    "        fake = self.Gnn(noise)\n",
    "        # batchSize * n * imgSize * imgSize\n",
    "        new = torch.ones(real.size(), ).to(device)\n",
    "        for k in range(batchSize):\n",
    "            sigma = float(torch.rand(1, 1))\n",
    "            new[k] = sigma*real[k] + (1-sigma)*fake[k]\n",
    "        pred1 = self.Dnn(fake)\n",
    "        pred2 = self.Dnn(new)\n",
    "        x_grad = torch.autograd.grad(pred2, new, torch.ones(\n",
    "            batchSize, 1).to(device), retain_graph=True)\n",
    "        D_loss = gploss(pred1, self.Dnn(real), x_grad[0])\n",
    "        self.Dnn.zero_grad()\n",
    "        D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        return D_loss\n",
    "\n",
    "    def step_D_new(self, real):\n",
    "        noise = torch.randn(batchSize, nz, 1, 1).to(device)\n",
    "        fake = self.Gnn(noise)      # batchSize * n * imgSize * imgSize\n",
    "        pred_fake = self.Dnn(fake).mean()\n",
    "        pred_real = self.Dnn(real).mean()\n",
    "        pred_real.backward(self.n_one)\n",
    "        pred_fake.backward(self.one)\n",
    "        D_loss = self.calc_gradient_penalty(real, fake)\n",
    "        D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        return pred_fake - pred_real + D_loss\n",
    "\n",
    "    def train(self, trainLoader):\n",
    "        z = torch.randn(batchSize, nz, 1, 1).to(device)\n",
    "        for j in range(epoch):\n",
    "            D_lossList = []\n",
    "            G_lossList = []\n",
    "            for i, (img, _) in enumerate(trainLoader, 0):\n",
    "                real = img.to(device)\n",
    "                self.Dnn.zero_grad()\n",
    "                D_loss = self.step_D_new(real)\n",
    "                if not i % n_D:\n",
    "                    self.Gnn.zero_grad()\n",
    "                    noise = torch.randn(batchSize, nz, 1, 1).to(device)\n",
    "                    G_loss = torch.mean(self.Dnn(self.Gnn(noise)))\n",
    "                    G_loss.backward(self.n_one)\n",
    "                    G_loss = - G_loss\n",
    "                    self.G_optim.step()\n",
    "\n",
    "                if not i % shotNum:\n",
    "                    print('[%03d,epoch%2d]  G_loss:%.6f,  D_loss:%.6f' % (i, j, G_loss, D_loss))\n",
    "                    if saveImg:\n",
    "                        save_image(self.Gnn(z).detach(), savePath +\n",
    "                                   '/epoch{}-num{}.jpg'.format(j+1, i), normalize=True)\n",
    "                        ############# save image from rand noise: ###############\n",
    "                        # tmp = torch.randn(batchSize, nz, 1, 1).to(device)\n",
    "                        # save_image(self.Gnn(tmp).detach(\n",
    "                        # ), savePath+'/rand-epoch{}-num{}.jpg'.format(j+1, i), normalize=True)\n",
    "\n",
    "            ######### one epoch trainning end #########\n",
    "            self.D_loss.append(D_lossList)\n",
    "            self.G_loss.append(G_lossList)\n",
    "            if not(j % saveNum) and saveModel:\n",
    "                self.saveModel(j+1)\n",
    "            self.saveLoss(dataPath)\n",
    "        print('############## train finish ! ################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-30T09:50:54.614Z"
    }
   },
   "outputs": [],
   "source": [
    "########################## Main: #############################\n",
    "if __name__ == '__main__':\n",
    "    trainLoader = DataLoader(\n",
    "        dataset=whyDataset(imgPath), batch_size=batchSize, shuffle=True, drop_last=True)\n",
    "    Gan = WGAN()\n",
    "    Gan.train(trainLoader)\n",
    "    if saveModel:\n",
    "        torch.save(Gan.Gnn.state_dict(),\n",
    "                   modelPath+\"/WGAN_G-epoch{}.pkl\".format(epoch))\n",
    "        torch.save(Gan.Dnn.state_dict(),\n",
    "                   modelPath+\"/WGAN_D-epoch-{}.pkl\".format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
